description: finetune_llama2

target:
  service: aml
  # name: tscience-a100-80g-eastus
  name: A100-80G-PCIE-westus3
  # name: V10032G
  # name: A100EastUS
  # name: openai-A10080G
  # name: A10080G
  # name: gpu-v100-32g
  # name: gpu-a100-80g


environment:
  image: pytorch/pytorch:2.0.1-cuda11.7-cudnn8-runtime
  image_setup:
    - apt-get -y update
    - apt-get -y install wget
    - apt-get -y install git
  setup:
    - pip install transformers==4.31.0
    - pip install accelerate==0.21.0
    - pip install bitsandbytes==0.40.0
    - pip install evaluate==0.4.0 scikit-learn==1.2.2 scipy typing_extensions einops==0.6.1
    - pip install datasets sentencepiece==0.1.99 setuptools rouge-score nltk openai
    - pip install tensorboard tensorboardX
    - pip install wandb==0.15.3
    - cd /opt/conda/lib/python3.10/site-packages/bitsandbytes
    - cp libbitsandbytes_cuda117.so libbitsandbytes_cpu.so

storage:
  output:
    storage_account_name: tsinterns
    container_name: t-qingru
    mount_dir: /mnt/t-qingru

code:
  local_dir: ../

jobs:
- name: qlora_alpagasus_iter0-2e-5-5e-5-alpha16
  sku: 1xG4
  process_count_per_node: 1
  submit_args:
    container_args:
      cpus: 32
  command:
    - CUDA_VISIBLE_DEVICES=0 torchrun --rdzv-backend=c10d --rdzv-endpoint=localhost:10 --nnodes=1 --nproc-per-node=1 qlora.py --ddp_find_unused_parameters False --model_name_or_path meta-llama/Llama-2-7b-hf --use_auth --output_dir /mnt/t-qingru/exp_results/qlora_replicate_alpagasus/alpha16/2e-5/seed0 --logging_steps 10  --save_strategy steps --data_seed 42 --save_steps 500 --save_total_limit 40 --evaluation_strategy steps --eval_dataset_size 1024  --max_eval_samples 1000 --per_device_eval_batch_size 1 --max_new_tokens 32 --dataloader_num_workers 1 --group_by_length --logging_strategy steps --remove_unused_columns False --do_train --do_eval --do_mmlu_eval --lora_r 64 --lora_alpha 16 --lora_modules all --double_quant --quant_type nf4 --bf16 --bits 4 --warmup_ratio 0.03 --lr_scheduler_type constant --gradient_checkpointing --dataset alpagasus --source_max_len 384 --target_max_len 128  --per_device_train_batch_size 1 --gradient_accumulation_steps 16 --max_steps 2000 --eval_steps 500 --learning_rate 2e-5 --adam_beta2 0.999  --max_grad_norm 0.3 --lora_dropout 0.1 --weight_decay 0.0  --seed 0 --cache_dir /mnt/t-qingru/cache/qlora_replicate --mmlu_split test &
    - CUDA_VISIBLE_DEVICES=1 torchrun --rdzv-backend=c10d --rdzv-endpoint=localhost:20 --nnodes=1 --nproc-per-node=1 qlora.py --ddp_find_unused_parameters False --model_name_or_path meta-llama/Llama-2-7b-hf --use_auth --output_dir /mnt/t-qingru/exp_results/qlora_replicate_alpagasus/alpha16/2e-5/seed1 --logging_steps 10  --save_strategy steps --data_seed 43 --save_steps 500 --save_total_limit 40 --evaluation_strategy steps --eval_dataset_size 1024  --max_eval_samples 1000 --per_device_eval_batch_size 1 --max_new_tokens 32 --dataloader_num_workers 1 --group_by_length --logging_strategy steps --remove_unused_columns False --do_train --do_eval --do_mmlu_eval --lora_r 64 --lora_alpha 16 --lora_modules all --double_quant --quant_type nf4 --bf16 --bits 4 --warmup_ratio 0.03 --lr_scheduler_type constant --gradient_checkpointing --dataset alpagasus --source_max_len 384 --target_max_len 128  --per_device_train_batch_size 1 --gradient_accumulation_steps 16 --max_steps 2000 --eval_steps 500 --learning_rate 2e-5 --adam_beta2 0.999  --max_grad_norm 0.3 --lora_dropout 0.1 --weight_decay 0.0  --seed 1 --cache_dir /mnt/t-qingru/cache/qlora_replicate --mmlu_split test &
    - CUDA_VISIBLE_DEVICES=2 torchrun --rdzv-backend=c10d --rdzv-endpoint=localhost:30 --nnodes=1 --nproc-per-node=1 qlora.py --ddp_find_unused_parameters False --model_name_or_path meta-llama/Llama-2-7b-hf --use_auth --output_dir /mnt/t-qingru/exp_results/qlora_replicate_alpagasus/alpha16/5e-5/seed2 --logging_steps 10  --save_strategy steps --data_seed 44 --save_steps 500 --save_total_limit 40 --evaluation_strategy steps --eval_dataset_size 1024  --max_eval_samples 1000 --per_device_eval_batch_size 1 --max_new_tokens 32 --dataloader_num_workers 1 --group_by_length --logging_strategy steps --remove_unused_columns False --do_train --do_eval --do_mmlu_eval --lora_r 64 --lora_alpha 16 --lora_modules all --double_quant --quant_type nf4 --bf16 --bits 4 --warmup_ratio 0.03 --lr_scheduler_type constant --gradient_checkpointing --dataset alpagasus --source_max_len 384 --target_max_len 128  --per_device_train_batch_size 1 --gradient_accumulation_steps 16 --max_steps 2000 --eval_steps 500 --learning_rate 5e-5 --adam_beta2 0.999  --max_grad_norm 0.3 --lora_dropout 0.1 --weight_decay 0.0  --seed 2 --cache_dir /mnt/t-qingru/cache/qlora_replicate --mmlu_split test &
    - sleep 3600
    - CUDA_VISIBLE_DEVICES=3 torchrun --rdzv-backend=c10d --rdzv-endpoint=localhost:40 --nnodes=1 --nproc-per-node=1 qlora.py --ddp_find_unused_parameters False --model_name_or_path meta-llama/Llama-2-7b-hf --use_auth --output_dir /mnt/t-qingru/exp_results/qlora_replicate_alpagasus/alpha16/5e-5/seed3 --logging_steps 10  --save_strategy steps --data_seed 45 --save_steps 500 --save_total_limit 40 --evaluation_strategy steps --eval_dataset_size 1024  --max_eval_samples 1000 --per_device_eval_batch_size 1 --max_new_tokens 32 --dataloader_num_workers 1 --group_by_length --logging_strategy steps --remove_unused_columns False --do_train --do_eval --do_mmlu_eval --lora_r 64 --lora_alpha 16 --lora_modules all --double_quant --quant_type nf4 --bf16 --bits 4 --warmup_ratio 0.03 --lr_scheduler_type constant --gradient_checkpointing --dataset alpagasus --source_max_len 384 --target_max_len 128  --per_device_train_batch_size 1 --gradient_accumulation_steps 16 --max_steps 2000 --eval_steps 500 --learning_rate 5e-5 --adam_beta2 0.999  --max_grad_norm 0.3 --lora_dropout 0.1 --weight_decay 0.0  --seed 3 --cache_dir /mnt/t-qingru/cache/qlora_replicate --mmlu_split test

- name: qlora_alpagasus_iter0-8e-5-2e-4-alpha16
  sku: 1xG4
  process_count_per_node: 1
  submit_args:
    container_args:
      cpus: 32
  command:
    - CUDA_VISIBLE_DEVICES=0 torchrun --rdzv-backend=c10d --rdzv-endpoint=localhost:10 --nnodes=1 --nproc-per-node=1 qlora.py --ddp_find_unused_parameters False --model_name_or_path meta-llama/Llama-2-7b-hf --use_auth --output_dir /mnt/t-qingru/exp_results/qlora_replicate_alpagasus/alpha16/8e-5/seed0 --logging_steps 10  --save_strategy steps --data_seed 42 --save_steps 500 --save_total_limit 40 --evaluation_strategy steps --eval_dataset_size 1024  --max_eval_samples 1000 --per_device_eval_batch_size 1 --max_new_tokens 32 --dataloader_num_workers 1 --group_by_length --logging_strategy steps --remove_unused_columns False --do_train --do_eval --do_mmlu_eval --lora_r 64 --lora_alpha 16 --lora_modules all --double_quant --quant_type nf4 --bf16 --bits 4 --warmup_ratio 0.03 --lr_scheduler_type constant --gradient_checkpointing --dataset alpagasus --source_max_len 384 --target_max_len 128  --per_device_train_batch_size 1 --gradient_accumulation_steps 16 --max_steps 2000 --eval_steps 500 --learning_rate 8e-5 --adam_beta2 0.999  --max_grad_norm 0.3 --lora_dropout 0.1 --weight_decay 0.0  --seed 0 --cache_dir /mnt/t-qingru/cache/qlora_replicate --mmlu_split test &
    - CUDA_VISIBLE_DEVICES=1 torchrun --rdzv-backend=c10d --rdzv-endpoint=localhost:20 --nnodes=1 --nproc-per-node=1 qlora.py --ddp_find_unused_parameters False --model_name_or_path meta-llama/Llama-2-7b-hf --use_auth --output_dir /mnt/t-qingru/exp_results/qlora_replicate_alpagasus/alpha16/8e-5/seed1 --logging_steps 10  --save_strategy steps --data_seed 43 --save_steps 500 --save_total_limit 40 --evaluation_strategy steps --eval_dataset_size 1024  --max_eval_samples 1000 --per_device_eval_batch_size 1 --max_new_tokens 32 --dataloader_num_workers 1 --group_by_length --logging_strategy steps --remove_unused_columns False --do_train --do_eval --do_mmlu_eval --lora_r 64 --lora_alpha 16 --lora_modules all --double_quant --quant_type nf4 --bf16 --bits 4 --warmup_ratio 0.03 --lr_scheduler_type constant --gradient_checkpointing --dataset alpagasus --source_max_len 384 --target_max_len 128  --per_device_train_batch_size 1 --gradient_accumulation_steps 16 --max_steps 2000 --eval_steps 500 --learning_rate 8e-5 --adam_beta2 0.999  --max_grad_norm 0.3 --lora_dropout 0.1 --weight_decay 0.0  --seed 1 --cache_dir /mnt/t-qingru/cache/qlora_replicate --mmlu_split test &
    - CUDA_VISIBLE_DEVICES=2 torchrun --rdzv-backend=c10d --rdzv-endpoint=localhost:30 --nnodes=1 --nproc-per-node=1 qlora.py --ddp_find_unused_parameters False --model_name_or_path meta-llama/Llama-2-7b-hf --use_auth --output_dir /mnt/t-qingru/exp_results/qlora_replicate_alpagasus/alpha16/2e-4/seed2 --logging_steps 10  --save_strategy steps --data_seed 44 --save_steps 500 --save_total_limit 40 --evaluation_strategy steps --eval_dataset_size 1024  --max_eval_samples 1000 --per_device_eval_batch_size 1 --max_new_tokens 32 --dataloader_num_workers 1 --group_by_length --logging_strategy steps --remove_unused_columns False --do_train --do_eval --do_mmlu_eval --lora_r 64 --lora_alpha 16 --lora_modules all --double_quant --quant_type nf4 --bf16 --bits 4 --warmup_ratio 0.03 --lr_scheduler_type constant --gradient_checkpointing --dataset alpagasus --source_max_len 384 --target_max_len 128  --per_device_train_batch_size 1 --gradient_accumulation_steps 16 --max_steps 2000 --eval_steps 500 --learning_rate 2e-4 --adam_beta2 0.999  --max_grad_norm 0.3 --lora_dropout 0.1 --weight_decay 0.0  --seed 2 --cache_dir /mnt/t-qingru/cache/qlora_replicate --mmlu_split test &
    - sleep 3600
    - CUDA_VISIBLE_DEVICES=3 torchrun --rdzv-backend=c10d --rdzv-endpoint=localhost:40 --nnodes=1 --nproc-per-node=1 qlora.py --ddp_find_unused_parameters False --model_name_or_path meta-llama/Llama-2-7b-hf --use_auth --output_dir /mnt/t-qingru/exp_results/qlora_replicate_alpagasus/alpha16/2e-4/seed3 --logging_steps 10  --save_strategy steps --data_seed 45 --save_steps 500 --save_total_limit 40 --evaluation_strategy steps --eval_dataset_size 1024  --max_eval_samples 1000 --per_device_eval_batch_size 1 --max_new_tokens 32 --dataloader_num_workers 1 --group_by_length --logging_strategy steps --remove_unused_columns False --do_train --do_eval --do_mmlu_eval --lora_r 64 --lora_alpha 16 --lora_modules all --double_quant --quant_type nf4 --bf16 --bits 4 --warmup_ratio 0.03 --lr_scheduler_type constant --gradient_checkpointing --dataset alpagasus --source_max_len 384 --target_max_len 128  --per_device_train_batch_size 1 --gradient_accumulation_steps 16 --max_steps 2000 --eval_steps 500 --learning_rate 2e-4 --adam_beta2 0.999  --max_grad_norm 0.3 --lora_dropout 0.1 --weight_decay 0.0  --seed 3 --cache_dir /mnt/t-qingru/cache/qlora_replicate --mmlu_split test

- name: qlora_alpagasus_iter1-2e-5-5e-5-alpha16
  sku: 1xG4
  process_count_per_node: 1
  submit_args:
    container_args:
      cpus: 32
  command:
    - CUDA_VISIBLE_DEVICES=0 torchrun --rdzv-backend=c10d --rdzv-endpoint=localhost:10 --nnodes=1 --nproc-per-node=1 qlora_svd.py --ddp_find_unused_parameters False --model_name_or_path meta-llama/Llama-2-7b-hf --use_auth --output_dir /mnt/t-qingru/exp_results/qlora_svd_alpagasus/iter1_alpha16/2e-5/seed0 --logging_steps 10  --save_strategy steps --data_seed 42 --save_steps 500 --save_total_limit 40 --evaluation_strategy steps --eval_dataset_size 1024  --max_eval_samples 1000 --per_device_eval_batch_size 1 --max_new_tokens 32 --dataloader_num_workers 1 --group_by_length --logging_strategy steps --remove_unused_columns False --do_train --do_eval --do_mmlu_eval --lora_r 64 --lora_alpha 16 --lora_modules all --double_quant --quant_type nf4 --bf16 --bits 4 --warmup_ratio 0.03 --lr_scheduler_type constant --gradient_checkpointing --dataset alpagasus --source_max_len 384 --target_max_len 128  --per_device_train_batch_size 1 --gradient_accumulation_steps 16 --max_steps 2000 --eval_steps 500 --learning_rate 2e-5 --adam_beta2 0.999  --max_grad_norm 0.3 --lora_dropout 0.1 --weight_decay 0.0  --seed 0 --cache_dir /mnt/t-qingru/cache/qlora_svd --num_bits 4 --num_iter 1 --reduced_rank 64 --path_to_model_zoo /mnt/t-qingru/yixiaoli_model_zoo --mmlu_split test --bf16 &
    - CUDA_VISIBLE_DEVICES=1 torchrun --rdzv-backend=c10d --rdzv-endpoint=localhost:20 --nnodes=1 --nproc-per-node=1 qlora_svd.py --ddp_find_unused_parameters False --model_name_or_path meta-llama/Llama-2-7b-hf --use_auth --output_dir /mnt/t-qingru/exp_results/qlora_svd_alpagasus/iter1_alpha16/2e-5/seed1 --logging_steps 10  --save_strategy steps --data_seed 43 --save_steps 500 --save_total_limit 40 --evaluation_strategy steps --eval_dataset_size 1024  --max_eval_samples 1000 --per_device_eval_batch_size 1 --max_new_tokens 32 --dataloader_num_workers 1 --group_by_length --logging_strategy steps --remove_unused_columns False --do_train --do_eval --do_mmlu_eval --lora_r 64 --lora_alpha 16 --lora_modules all --double_quant --quant_type nf4 --bf16 --bits 4 --warmup_ratio 0.03 --lr_scheduler_type constant --gradient_checkpointing --dataset alpagasus --source_max_len 384 --target_max_len 128  --per_device_train_batch_size 1 --gradient_accumulation_steps 16 --max_steps 2000 --eval_steps 500 --learning_rate 2e-5 --adam_beta2 0.999  --max_grad_norm 0.3 --lora_dropout 0.1 --weight_decay 0.0  --seed 1 --cache_dir /mnt/t-qingru/cache/qlora_svd --num_bits 4 --num_iter 1 --reduced_rank 64 --path_to_model_zoo /mnt/t-qingru/yixiaoli_model_zoo --mmlu_split test --bf16 &
    - CUDA_VISIBLE_DEVICES=2 torchrun --rdzv-backend=c10d --rdzv-endpoint=localhost:30 --nnodes=1 --nproc-per-node=1 qlora_svd.py --ddp_find_unused_parameters False --model_name_or_path meta-llama/Llama-2-7b-hf --use_auth --output_dir /mnt/t-qingru/exp_results/qlora_svd_alpagasus/iter1_alpha16/5e-5/seed2 --logging_steps 10  --save_strategy steps --data_seed 44 --save_steps 500 --save_total_limit 40 --evaluation_strategy steps --eval_dataset_size 1024  --max_eval_samples 1000 --per_device_eval_batch_size 1 --max_new_tokens 32 --dataloader_num_workers 1 --group_by_length --logging_strategy steps --remove_unused_columns False --do_train --do_eval --do_mmlu_eval --lora_r 64 --lora_alpha 16 --lora_modules all --double_quant --quant_type nf4 --bf16 --bits 4 --warmup_ratio 0.03 --lr_scheduler_type constant --gradient_checkpointing --dataset alpagasus --source_max_len 384 --target_max_len 128  --per_device_train_batch_size 1 --gradient_accumulation_steps 16 --max_steps 2000 --eval_steps 500 --learning_rate 5e-5 --adam_beta2 0.999  --max_grad_norm 0.3 --lora_dropout 0.1 --weight_decay 0.0  --seed 2 --cache_dir /mnt/t-qingru/cache/qlora_svd --num_bits 4 --num_iter 1 --reduced_rank 64 --path_to_model_zoo /mnt/t-qingru/yixiaoli_model_zoo --mmlu_split test --bf16 &
    - sleep 3600
    - CUDA_VISIBLE_DEVICES=3 torchrun --rdzv-backend=c10d --rdzv-endpoint=localhost:40 --nnodes=1 --nproc-per-node=1 qlora_svd.py --ddp_find_unused_parameters False --model_name_or_path meta-llama/Llama-2-7b-hf --use_auth --output_dir /mnt/t-qingru/exp_results/qlora_svd_alpagasus/iter1_alpha16/5e-5/seed3 --logging_steps 10  --save_strategy steps --data_seed 45 --save_steps 500 --save_total_limit 40 --evaluation_strategy steps --eval_dataset_size 1024  --max_eval_samples 1000 --per_device_eval_batch_size 1 --max_new_tokens 32 --dataloader_num_workers 1 --group_by_length --logging_strategy steps --remove_unused_columns False --do_train --do_eval --do_mmlu_eval --lora_r 64 --lora_alpha 16 --lora_modules all --double_quant --quant_type nf4 --bf16 --bits 4 --warmup_ratio 0.03 --lr_scheduler_type constant --gradient_checkpointing --dataset alpagasus --source_max_len 384 --target_max_len 128  --per_device_train_batch_size 1 --gradient_accumulation_steps 16 --max_steps 2000 --eval_steps 500 --learning_rate 5e-5 --adam_beta2 0.999  --max_grad_norm 0.3 --lora_dropout 0.1 --weight_decay 0.0  --seed 3 --cache_dir /mnt/t-qingru/cache/qlora_svd --num_bits 4 --num_iter 1 --reduced_rank 64 --path_to_model_zoo /mnt/t-qingru/yixiaoli_model_zoo --mmlu_split test --bf16

- name: qlora_alpagasus_iter1-8e-5-2e-4-alpha16
  sku: 1xG4
  process_count_per_node: 1
  submit_args:
    container_args:
      cpus: 32
  command:
    - CUDA_VISIBLE_DEVICES=0 torchrun --rdzv-backend=c10d --rdzv-endpoint=localhost:10 --nnodes=1 --nproc-per-node=1 qlora_svd.py --ddp_find_unused_parameters False --model_name_or_path meta-llama/Llama-2-7b-hf --use_auth --output_dir /mnt/t-qingru/exp_results/qlora_svd_alpagasus/iter1_alpha16/8e-5/seed0 --logging_steps 10  --save_strategy steps --data_seed 42 --save_steps 500 --save_total_limit 40 --evaluation_strategy steps --eval_dataset_size 1024  --max_eval_samples 1000 --per_device_eval_batch_size 1 --max_new_tokens 32 --dataloader_num_workers 1 --group_by_length --logging_strategy steps --remove_unused_columns False --do_train --do_eval --do_mmlu_eval --lora_r 64 --lora_alpha 16 --lora_modules all --double_quant --quant_type nf4 --bf16 --bits 4 --warmup_ratio 0.03 --lr_scheduler_type constant --gradient_checkpointing --dataset alpagasus --source_max_len 384 --target_max_len 128  --per_device_train_batch_size 1 --gradient_accumulation_steps 16 --max_steps 2000 --eval_steps 500 --learning_rate 8e-5 --adam_beta2 0.999  --max_grad_norm 0.3 --lora_dropout 0.1 --weight_decay 0.0  --seed 0 --cache_dir /mnt/t-qingru/cache/qlora_svd --num_bits 4 --num_iter 1 --reduced_rank 64 --path_to_model_zoo /mnt/t-qingru/yixiaoli_model_zoo --mmlu_split test --bf16 &
    - CUDA_VISIBLE_DEVICES=1 torchrun --rdzv-backend=c10d --rdzv-endpoint=localhost:20 --nnodes=1 --nproc-per-node=1 qlora_svd.py --ddp_find_unused_parameters False --model_name_or_path meta-llama/Llama-2-7b-hf --use_auth --output_dir /mnt/t-qingru/exp_results/qlora_svd_alpagasus/iter1_alpha16/8e-5/seed1 --logging_steps 10  --save_strategy steps --data_seed 43 --save_steps 500 --save_total_limit 40 --evaluation_strategy steps --eval_dataset_size 1024  --max_eval_samples 1000 --per_device_eval_batch_size 1 --max_new_tokens 32 --dataloader_num_workers 1 --group_by_length --logging_strategy steps --remove_unused_columns False --do_train --do_eval --do_mmlu_eval --lora_r 64 --lora_alpha 16 --lora_modules all --double_quant --quant_type nf4 --bf16 --bits 4 --warmup_ratio 0.03 --lr_scheduler_type constant --gradient_checkpointing --dataset alpagasus --source_max_len 384 --target_max_len 128  --per_device_train_batch_size 1 --gradient_accumulation_steps 16 --max_steps 2000 --eval_steps 500 --learning_rate 8e-5 --adam_beta2 0.999  --max_grad_norm 0.3 --lora_dropout 0.1 --weight_decay 0.0  --seed 1 --cache_dir /mnt/t-qingru/cache/qlora_svd --num_bits 4 --num_iter 1 --reduced_rank 64 --path_to_model_zoo /mnt/t-qingru/yixiaoli_model_zoo --mmlu_split test --bf16 &
    - CUDA_VISIBLE_DEVICES=2 torchrun --rdzv-backend=c10d --rdzv-endpoint=localhost:30 --nnodes=1 --nproc-per-node=1 qlora_svd.py --ddp_find_unused_parameters False --model_name_or_path meta-llama/Llama-2-7b-hf --use_auth --output_dir /mnt/t-qingru/exp_results/qlora_svd_alpagasus/iter1_alpha16/2e-4/seed2 --logging_steps 10  --save_strategy steps --data_seed 44 --save_steps 500 --save_total_limit 40 --evaluation_strategy steps --eval_dataset_size 1024  --max_eval_samples 1000 --per_device_eval_batch_size 1 --max_new_tokens 32 --dataloader_num_workers 1 --group_by_length --logging_strategy steps --remove_unused_columns False --do_train --do_eval --do_mmlu_eval --lora_r 64 --lora_alpha 16 --lora_modules all --double_quant --quant_type nf4 --bf16 --bits 4 --warmup_ratio 0.03 --lr_scheduler_type constant --gradient_checkpointing --dataset alpagasus --source_max_len 384 --target_max_len 128  --per_device_train_batch_size 1 --gradient_accumulation_steps 16 --max_steps 2000 --eval_steps 500 --learning_rate 2e-4 --adam_beta2 0.999  --max_grad_norm 0.3 --lora_dropout 0.1 --weight_decay 0.0  --seed 2 --cache_dir /mnt/t-qingru/cache/qlora_svd --num_bits 4 --num_iter 1 --reduced_rank 64 --path_to_model_zoo /mnt/t-qingru/yixiaoli_model_zoo --mmlu_split test --bf16 &
    - sleep 3600
    - CUDA_VISIBLE_DEVICES=3 torchrun --rdzv-backend=c10d --rdzv-endpoint=localhost:40 --nnodes=1 --nproc-per-node=1 qlora_svd.py --ddp_find_unused_parameters False --model_name_or_path meta-llama/Llama-2-7b-hf --use_auth --output_dir /mnt/t-qingru/exp_results/qlora_svd_alpagasus/iter1_alpha16/2e-4/seed3 --logging_steps 10  --save_strategy steps --data_seed 45 --save_steps 500 --save_total_limit 40 --evaluation_strategy steps --eval_dataset_size 1024  --max_eval_samples 1000 --per_device_eval_batch_size 1 --max_new_tokens 32 --dataloader_num_workers 1 --group_by_length --logging_strategy steps --remove_unused_columns False --do_train --do_eval --do_mmlu_eval --lora_r 64 --lora_alpha 16 --lora_modules all --double_quant --quant_type nf4 --bf16 --bits 4 --warmup_ratio 0.03 --lr_scheduler_type constant --gradient_checkpointing --dataset alpagasus --source_max_len 384 --target_max_len 128  --per_device_train_batch_size 1 --gradient_accumulation_steps 16 --max_steps 2000 --eval_steps 500 --learning_rate 2e-4 --adam_beta2 0.999  --max_grad_norm 0.3 --lora_dropout 0.1 --weight_decay 0.0  --seed 3 --cache_dir /mnt/t-qingru/cache/qlora_svd --num_bits 4 --num_iter 1 --reduced_rank 64 --path_to_model_zoo /mnt/t-qingru/yixiaoli_model_zoo --mmlu_split test --bf16

